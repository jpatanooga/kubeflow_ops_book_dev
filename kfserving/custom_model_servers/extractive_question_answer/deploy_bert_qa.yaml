apiVersion: serving.kubeflow.org/v1alpha2
kind: InferenceService
metadata:
  labels:
    controller-tools.k8s.io: "1.0"
  name: kfserving-custom-model
spec:
  default:
    predictor:
      custom:
        container:
          image: pattersonconsulting/kfserving-custom-model
          resources:
            requests:
              memory: "4096Mi"
              cpu: "250m"
            limits:
              memory: "4096Mi"
              cpu: "500m"          